---
layout:     post                   
title:      计算机组成原理            
subtitle:   cpu cache知识总结           
date:       2018-09-12             
author:     west                   
header-img: img/post_green.jpg   
catalog: true                       而本文的核心在与讲解cache
tags:                             
    - cpu
---

### 相关知识

#### CPU Cache相关

##### 架构

AMD Athlon 处理器架构
- 望这张图，眼花缭乱？其实现代的CPU可以简化为两部分：cpu核心，cache。而本文的核心在于讲解cache。
- Athlon的缓存架构为2层:L1和L2。

<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/6a/Athlon_arch.png/1280px-Athlon_arch.png"  alt="cpu缓存行体系" height="400" weight="300"/>

</br>
</br>
以Athlon为引子，接下来我们讲重点来了解cpu缓存架构。在这之前，我们需要了解下CPU的相关属性，以帮助理解为何需要cpu缓存。

##### 相关属性

首先是cpu的频率，其决定了其每秒能传输数据量，也称为cpu带宽。</br>

例如，配置为2GHZ,内部带宽为64的CPU，传输效率为16GB/s。计算公式为：
```
// cpu 带宽计算公式
前端总线带宽＝系统外频×N倍速×64位总线位宽/8
```
其次是内存的频率，其内存带宽的计算公式为：

```
// 内存带宽计算公式,'data per clock' 默认为1 
内存带宽 = width (number of bits) x clock rate x data per clock / 8
```

根据计算公式，配置为2GHZ的CPU带宽为16GB/s，DDR2-800的内存带宽约为 6,400 MB/s – 12,800 MB/s，两者差距最大为4倍左右。当CPU从内存获取数据时，将耗费大量的时间来等待数据到达，这意味着性能将降为原先1/4左右，这让人无法容忍。

**所以有了CPU缓存。**

---

##### CPU缓存

为了最大程度发挥CPU的性能，就得让CPU一直在忙，所以目的在于减少其等待的时间。因此CPU缓存出现。

缓存出现的目的是为了解决CPU与内存的巨大的数据传输能力差距问题，其作为一个缓冲，提前将数据存储在相应的缓存，当CPU读取数据时，直接从缓存读取而不是从内存中读，从而减少CPU等待。

下图为CPU的访问各个组件需要的时间：

**可以很明显地看到，cpu访问内存对比访问缓存是非常耗时的**。

<img src="http://7xp2eu.com1.z0.glb.clouddn.com/hierarchy%20cache.png"  alt="cpu缓存行体系" height="350" weight="300"/>

</br>
</br>

常见的CPU缓存有L1，L2，L3等：

<img src="http://7xp2eu.com1.z0.glb.clouddn.com/mac_cpu_cache_info.png"  alt="cpu缓存行体系" height="400" weight="300"/>

</br>
</br>

**所以CPU缓存是如何组织数据呢？答案为缓存行(cache line)**

##### Cache Line

常见的CPU缓存行与内存行对应结构设计:
- L1分为instrution,data两部分
- L2分存储数据，不区分instrution和data。再提一句，不同的cpu实现中，L2可以存一份L1中的数据，也可以不存，视具体的CPU而定。
- L3 size最大，同时为多核共享(在现在的主流计算机中，L1+L2为cpu私有)

<img src="https://qph.fs.quoracdn.net/main-qimg-a40cfe3886520103efec5f38d12d478a"  alt="cpu缓存行体系" height="400" weight="300"/>

</br>
</br>

经典的缓存行结构设计有三种，上图的full,direct associative是两种极端：
- full 结构结构表示数据可以缓存在缓存行的任意位置，cache 命中率高，但相对应的read，write数据时实现复杂。
- direct 结构表示数据对应到一个缓存，cache命中率低，但相对应的read,write数据时实现简单。

两者都不是最优选项，而xx-way是对上面两者的折中，其中xx=2^n。比如 **AMD Athlon为2-way结构， Ryzen-7-2700 为8-way结构**。

更多的CPU缓存行与内存行对应结构的相关问题可见 [wiki](https://en.wikipedia.org/wiki/CPU_cache)

另外，目前的主流计算机CPU缓存行长度为64bit，了解这个可以帮助我们理解java8提供的@Contented注解为何填充可以提供性能的来龙去脉，其实就是填充缓存行，避免缓存行污染从而导致每次写缓存行都要将数据刷回内存，避免一来一回地访问内存，从而提高性能。

更进一步可以看：
- [R大知乎-Java伪共享问题](https://www.zhihu.com/question/54812014/answer/141881795)
- [并发库disruptor](https://github.com/LMAX-Exchange/disruptor)

最后，我们需要谈谈缓存行中的数据的read,write问题:
- 对于read,要考虑的是找到一个缓存行存放数据，这其中涉及缓存满时旧数据的淘汰算法问题
- 对于write,常见的写入方式有write-back,write-through，在多核环境下，会带来cpu的数据一致性问题。**日后再来补充 todo**。
    

## 参考

- [cpu-cache-wiki](https://en.wikipedia.org/wiki/CPU_cache)
- [cache(computing)-wiki](https://en.wikipedia.org/wiki/Cache_(computing))
- [How L1 and L2 CPU Caches Work, and Why They’re an Essential Part of Modern Chips](https://www.extremetech.com/extreme/188776-how-l1-and-l2-cpu-caches-work-and-why-theyre-an-essential-part-of-modern-chips)
- [多处理器编程：从缓存一致性到内存模型](https://zhuanlan.zhihu.com/p/35386457)

